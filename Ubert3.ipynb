{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7r7cfW1Nw4Ym",
        "outputId": "99a5f1aa-8c30-4e1c-90ea-e251fd110a3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ij8dgEGzxHXf",
        "outputId": "90f7ca87-06a1-4087-f350-c7cee390f127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Python version of the evaluation script from CoNLL'00-\n",
        "\n",
        "# Intentional differences:\n",
        "# - accept any space as delimiter by default\n",
        "# - optional file argument (default STDIN)\n",
        "# - option to set boundary (-b argument)\n",
        "# - LaTeX output (-l argument) not supported\n",
        "# - raw tags (-r argument) not supported\n",
        "\n",
        "import sys\n",
        "import re\n",
        "\n",
        "from collections import defaultdict, namedtuple\n",
        "\n",
        "ANY_SPACE = '<SPACE>'\n",
        "\n",
        "class FormatError(Exception):\n",
        "    pass\n",
        "\n",
        "Metrics = namedtuple('Metrics', 'tp fp fn prec rec fscore')\n",
        "\n",
        "class EvalCounts(object):\n",
        "    def __init__(self):\n",
        "        self.correct_chunk = 0    # number of correctly identified chunks\n",
        "        self.correct_tags = 0     # number of correct chunk tags\n",
        "        self.found_correct = 0    # number of chunks in corpus\n",
        "        self.found_guessed = 0    # number of identified chunks\n",
        "        self.token_counter = 0    # token counter (ignores sentence breaks)\n",
        "\n",
        "        # counts by type\n",
        "        self.t_correct_chunk = defaultdict(int)\n",
        "        self.t_found_correct = defaultdict(int)\n",
        "        self.t_found_guessed = defaultdict(int)\n",
        "\n",
        "def parse_args(argv):\n",
        "    import argparse\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description='evaluate tagging results using CoNLL criteria',\n",
        "        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n",
        "    )\n",
        "    arg = parser.add_argument\n",
        "    arg('-b', '--boundary', metavar='STR', default='-X-',\n",
        "        help='sentence boundary')\n",
        "    arg('-d', '--delimiter', metavar='CHAR', default=ANY_SPACE,\n",
        "        help='character delimiting items in input')\n",
        "    arg('-o', '--otag', metavar='CHAR', default='O',\n",
        "        help='alternative outside tag')\n",
        "    arg('file', nargs='?', default=None)\n",
        "    return parser.parse_args(argv)\n",
        "\n",
        "def parse_tag(t):\n",
        "    m = re.match(r'^([^-]*)-(.*)$', t)\n",
        "    return m.groups() if m else (t, '')\n",
        "\n",
        "# ... [rest of the script remains unchanged up to the evaluate function]\n",
        "\n",
        "def evaluate(iterable, options=None):\n",
        "    if options is None:\n",
        "        options = parse_args([])    # use defaults\n",
        "\n",
        "    counts = EvalCounts()\n",
        "    num_features = None       # number of features per line\n",
        "\n",
        "    for line in iterable:\n",
        "        line = line.rstrip('\\r\\n')\n",
        "\n",
        "        if options.delimiter == ANY_SPACE:\n",
        "            features = line.split()\n",
        "        else:\n",
        "            features = line.split(options.delimiter)\n",
        "\n",
        "        if num_features is None:\n",
        "            num_features = len(features)\n",
        "        elif num_features != len(features) and len(features) != 0:\n",
        "            raise FormatError('unexpected number of features: %d (%d)' %\n",
        "                              (len(features), num_features))\n",
        "\n",
        "        if len(features) == 0 or features[0] == options.boundary:\n",
        "            continue\n",
        "        if len(features) < 2:\n",
        "            raise FormatError('unexpected number of features in line %s' % line)\n",
        "\n",
        "        guessed, correct = features[-2], features[-1]  # Modify this line if the order is different\n",
        "\n",
        "        # Start and end of chunks are just the tags themselves in your format\n",
        "        start_correct = correct != options.otag\n",
        "        start_guessed = guessed != options.otag\n",
        "        end_correct = start_correct\n",
        "        end_guessed = start_guessed\n",
        "\n",
        "        if start_correct:\n",
        "            counts.found_correct += 1\n",
        "            counts.t_found_correct[correct] += 1\n",
        "        if start_guessed:\n",
        "            counts.found_guessed += 1\n",
        "            counts.t_found_guessed[guessed] += 1\n",
        "        if correct == guessed:\n",
        "            counts.correct_tags += 1\n",
        "            if start_guessed:\n",
        "                counts.correct_chunk += 1\n",
        "                counts.t_correct_chunk[guessed] += 1\n",
        "\n",
        "        counts.token_counter += 1\n",
        "\n",
        "    return counts\n",
        "\n",
        "# ... [rest of the script remains unchanged]\n",
        "\n",
        "\n",
        "def uniq(iterable):\n",
        "  seen = set()\n",
        "  return [i for i in iterable if not (i in seen or seen.add(i))]\n",
        "\n",
        "def calculate_metrics(correct, guessed, total):\n",
        "    tp, fp, fn = correct, guessed-correct, total-correct\n",
        "    p = 0 if tp + fp == 0 else 1.*tp / (tp + fp)\n",
        "    r = 0 if tp + fn == 0 else 1.*tp / (tp + fn)\n",
        "    f = 0 if p + r == 0 else 2 * p * r / (p + r)\n",
        "    return Metrics(tp, fp, fn, p, r, f)\n",
        "\n",
        "def metrics(counts):\n",
        "    c = counts\n",
        "    overall = calculate_metrics(\n",
        "        c.correct_chunk, c.found_guessed, c.found_correct\n",
        "    )\n",
        "    by_type = {}\n",
        "    # print(c.t_found_guessed.keys())\n",
        "    # print(uniq(c.t_found_correct.keys() + c.t_found_guessed.keys()))\n",
        "    # dict_keys = c.t_found_correct.copy()\n",
        "    # dict_keys.update(c.t_found_guessed.keys)\n",
        "    list_keys = list(c.t_found_correct.keys())\n",
        "    list_keys += list(c.t_found_guessed.keys())\n",
        "\n",
        "    for t in set(list_keys):  # uniq(c.t_found_correct.keys() + c.t_found_guessed.keys()):\n",
        "        by_type[t] = calculate_metrics(\n",
        "            c.t_correct_chunk[t], c.t_found_guessed[t], c.t_found_correct[t]\n",
        "        )\n",
        "    return overall, by_type\n",
        "\n",
        "def report(counts, out=None):\n",
        "    if out is None:\n",
        "        out = sys.stdout\n",
        "\n",
        "    overall, by_type = metrics(counts)\n",
        "\n",
        "    c = counts\n",
        "    out.write('processed %d tokens with %d phrases; ' %\n",
        "              (c.token_counter, c.found_correct))\n",
        "    out.write('found: %d phrases; correct: %d.\\n' %\n",
        "              (c.found_guessed, c.correct_chunk))\n",
        "\n",
        "    results_arr = []\n",
        "\n",
        "    if c.token_counter > 0:\n",
        "        out.write('accuracy: %6.2f%%; ' %\n",
        "                  (100.*c.correct_tags/c.token_counter))\n",
        "        out.write('precision: %6.2f%%; ' % (100.*overall.prec))\n",
        "        out.write('recall: %6.2f%%; ' % (100.*overall.rec))\n",
        "        out.write('FB1: %6.2f\\n' % (100.*overall.fscore))\n",
        "\n",
        "    for i, m in sorted(by_type.items()):\n",
        "        out.write('%17s: ' % i)\n",
        "        out.write('precision: %6.2f%%; ' % (100.*m.prec))\n",
        "        out.write('recall: %6.2f%%; ' % (100.*m.rec))\n",
        "        out.write('FB1: %6.2f  %d\\n' % (100.*m.fscore, c.t_found_guessed[i]))\n",
        "        results_arr.append(100.*m.fscore)\n",
        "\n",
        "    results_arr.append(100.*overall.fscore)\n",
        "    return overall.fscore, results_arr\n",
        "\n",
        "def end_of_chunk(prev_tag, tag, prev_type, type_):\n",
        "    # check if a chunk ended between the previous and current word\n",
        "    # arguments: previous and current chunk tags, previous and current types\n",
        "    chunk_end = False\n",
        "\n",
        "    if prev_tag == 'E': chunk_end = True\n",
        "    if prev_tag == 'S': chunk_end = True\n",
        "\n",
        "    if prev_tag == 'B' and tag == 'B': chunk_end = True\n",
        "    if prev_tag == 'B' and tag == 'S': chunk_end = True\n",
        "    if prev_tag == 'B' and tag == 'O': chunk_end = True\n",
        "    if prev_tag == 'I' and tag == 'B': chunk_end = True\n",
        "    if prev_tag == 'I' and tag == 'S': chunk_end = True\n",
        "    if prev_tag == 'I' and tag == 'O': chunk_end = True\n",
        "\n",
        "    if prev_tag != 'O' and prev_tag != '.' and prev_type != type_:\n",
        "        chunk_end = True\n",
        "\n",
        "    # these chunks are assumed to have length 1\n",
        "    if prev_tag == ']': chunk_end = True\n",
        "    if prev_tag == '[': chunk_end = True\n",
        "\n",
        "    return chunk_end\n",
        "\n",
        "def start_of_chunk(prev_tag, tag, prev_type, type_):\n",
        "    # check if a chunk started between the previous and current word\n",
        "    # arguments: previous and current chunk tags, previous and current types\n",
        "    chunk_start = False\n",
        "\n",
        "    if tag == 'B': chunk_start = True\n",
        "    if tag == 'S': chunk_start = True\n",
        "\n",
        "    if prev_tag == 'E' and tag == 'E': chunk_start = True\n",
        "    if prev_tag == 'E' and tag == 'I': chunk_start = True\n",
        "    if prev_tag == 'S' and tag == 'E': chunk_start = True\n",
        "    if prev_tag == 'S' and tag == 'I': chunk_start = True\n",
        "    if prev_tag == 'O' and tag == 'E': chunk_start = True\n",
        "    if prev_tag == 'O' and tag == 'I': chunk_start = True\n",
        "\n",
        "    if tag != 'O' and tag != '.' and prev_type != type_:\n",
        "        chunk_start = True\n",
        "\n",
        "    # these chunks are assumed to have length 1\n",
        "    if tag == '[': chunk_start = True\n",
        "    if tag == ']': chunk_start = True\n",
        "\n",
        "    return chunk_start\n",
        "\n",
        "def eval_f1score(file_):\n",
        "\n",
        "    with open(file_) as f:\n",
        "        counts = evaluate(f)\n",
        "    f1score, fscore_arr = report(counts)\n",
        "    print(fscore_arr)\n",
        "\n",
        "    return f1score, fscore_arr\n",
        "\n",
        "# def main():\n",
        "#     print(eval_f1score('test.txt'))\n",
        "# if __name__ == '__main__':\n",
        "#     main()"
      ],
      "metadata": {
        "id": "2RwltQyQxhRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import namedtuple\n",
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "# from conlleval import eval_f1score\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import AutoTokenizer, AutoModel, BertPreTrainedModel, BertModel, AdamW"
      ],
      "metadata": {
        "id": "YAK7r7L4ONpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UppO4OLYO3rx",
        "outputId": "bae0318c-2042-4a10-e842-854180358d68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q_qniirXSzEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Paths for the dataset and the split files\n",
        "dataset_path = '/content/drive/My Drive/mk-pucit.txt'\n",
        "train_path = '/content/drive/My Drive/Dataset/train_dataset.txt'\n",
        "val_path = '/content/drive/My Drive/Dataset/val_dataset.txt'\n",
        "test_path = '/content/drive/My Drive/Dataset/test_dataset.txt'\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv(dataset_path, delimiter='\\t', header=None)\n",
        "\n",
        "# Split the dataset into training and temporary dataset\n",
        "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
        "\n",
        "# Split the temporary dataset into validation and test dataset\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
        "\n",
        "# Save the datasets to Google Drive\n",
        "train_df.to_csv(train_path, sep='\\t', index=False, header=False)\n",
        "val_df.to_csv(val_path, sep='\\t', index=False, header=False)\n",
        "test_df.to_csv(test_path, sep='\\t', index=False, header=False)"
      ],
      "metadata": {
        "id": "NvfqI46mPBTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TRAIN = '/content/drive/My Drive/Dataset/train_dataset.txt'\n",
        "PATH_VAL = '/content/drive/My Drive/Dataset/val_dataset.txt'\n",
        "PATH_TEST = '/content/drive/My Drive/Dataset/test_dataset.txt'\n",
        "# Define a function to read the data from a given path\n",
        "def read_data(path):\n",
        "    # Assuming the file is tab-separated and has no header\n",
        "    # Adjust the parameters accordingly if this is not the case\n",
        "    data = pd.read_csv(path, delimiter='\\t', header=None)\n",
        "    return data\n",
        "\n",
        "# Read the datasets\n",
        "train_data = read_data(PATH_TRAIN)\n",
        "val_data = read_data(PATH_VAL)\n",
        "test_data = read_data(PATH_TEST)\n",
        "\n",
        "# Check the first few entries of the training data\n",
        "print(train_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hS17xamATFE2",
        "outputId": "b299032a-df43-42f3-c844-060a9fd439b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      0      1\n",
            "0    سے  Other\n",
            "1    پر  Other\n",
            "2    جی  Other\n",
            "3   ٹیم  Other\n",
            "4  ایسے  Other\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_to_id = {\n",
        "    \"Other\": 0,\n",
        "    \"Organization\": 1,\n",
        "    \"Person\": 2,\n",
        "    \"Location\": 3  # Assuming you have 'Location' entities as well.\n",
        "    # Add any other entities you might have in your dataset\n",
        "}\n",
        "\n",
        "id_to_label = {value: key for key, value in label_to_id.items()}"
      ],
      "metadata": {
        "id": "6IUSXNuqU3sX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urdu_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\", do_lower_case=False)"
      ],
      "metadata": {
        "id": "yV2PR4lzVgYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_label(label):\n",
        "    if \"Organization\" in label:\n",
        "        return \"Organization\"\n",
        "    elif \"Person\" in label:\n",
        "        return \"Person\"\n",
        "    elif \"Location\" in label:\n",
        "        return \"Location\"\n",
        "    elif \"Other\" in label:\n",
        "        return \"Other\"\n",
        "    else:\n",
        "        return \"Other\"  # Default case if label is not recognized\n"
      ],
      "metadata": {
        "id": "Th7cOqQGVhYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import namedtuple\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "class UrduNERDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, label_to_id, max_length):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.label_to_id = label_to_id\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        labels = self.labels[idx]\n",
        "        # Tokenize the text and map labels to token ids\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            is_split_into_words=True,  # Important for word-level tasks\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        input_ids = encoding['input_ids'].flatten()\n",
        "        attention_mask = encoding['attention_mask'].flatten()\n",
        "\n",
        "        # Create a list to hold the label ids which we will create in the next loop\n",
        "        label_ids = []\n",
        "\n",
        "        # Here we need to map each token with its corresponding label.\n",
        "        # Special tokens will get a label of -100 by default, which will be ignored in the loss function.\n",
        "        last_word_id = None\n",
        "        for word_id in encoding.word_ids():\n",
        "            if word_id is None or word_id != last_word_id:  # Special or new word token\n",
        "                label_ids.append(label_to_id[labels[word_id]] if word_id is not None else -100)\n",
        "            else:  # Subword token\n",
        "                label_ids.append(-100)\n",
        "            last_word_id = word_id\n",
        "\n",
        "        label_ids = label_ids[:self.max_length]  # Truncate labels to `max_length`\n",
        "        label_ids += [-100] * (self.max_length - len(label_ids))  # Pad label_ids\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'labels': torch.tensor(label_ids, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "def read_dataset(path):\n",
        "    with open(path, 'r', encoding='utf-8') as file:\n",
        "        lines = file.read().splitlines()\n",
        "\n",
        "    # Split the dataset into tokens and labels\n",
        "    tokens, labels = [], []\n",
        "    texts, label_sequences = [], []\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":\n",
        "            if tokens:\n",
        "                texts.append(tokens)\n",
        "                label_sequences.append(labels)\n",
        "                tokens, labels = [], []\n",
        "        else:\n",
        "            token, label = line.split('\\t')\n",
        "            tokens.append(token)\n",
        "            labels.append(label)\n",
        "\n",
        "    # Check if the last line was the end of a sentence\n",
        "    if tokens:\n",
        "        texts.append(tokens)\n",
        "        label_sequences.append(labels)\n",
        "\n",
        "    return texts, label_sequences\n",
        "\n",
        "def preprocess_data(filepath, tokenizer, label_to_id, max_length):\n",
        "    # Read the raw text and labels\n",
        "    raw_texts, raw_labels = read_dataset(filepath)\n",
        "\n",
        "    # Tokenize and align labels with subword tokens\n",
        "    dataset = UrduNERDataset(raw_texts, raw_labels, tokenizer, label_to_id, max_length)\n",
        "\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "Pu-VUiedV18_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_to_tensors(dataset):\n",
        "    tensors_input_ids = []\n",
        "    tensors_input_mask = []\n",
        "    tensors_label_ids = []\n",
        "    for i in dataset:\n",
        "        tensors_input_ids.append(i.input_ids)\n",
        "        tensors_input_mask.append(i.input_mask)\n",
        "        tensors_label_ids.append(i.label_ids)\n",
        "\n",
        "    return torch.tensor(tensors_input_ids), torch.tensor(tensors_input_mask), torch.tensor(tensors_label_ids)"
      ],
      "metadata": {
        "id": "WqY_ktTNWeSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModifiedBertForTokenClassification(BertPreTrainedModel):\n",
        "    def __init__(self, config, num_labels=4):  # Set num_labels to the number of entity types you have\n",
        "        super().__init__(config)\n",
        "        self.num_labels = num_labels\n",
        "\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, self.num_labels)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        labels=None,\n",
        "    ):\n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "        )\n",
        "\n",
        "        sequence_output = outputs[0]\n",
        "\n",
        "        sequence_output = self.dropout(sequence_output)\n",
        "        logits = self.classifier(sequence_output)\n",
        "\n",
        "        outputs = (logits,) + outputs[2:]  # Add hidden states and attention if they are here\n",
        "\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            # Only keep active parts of the loss\n",
        "            if attention_mask is not None:\n",
        "                active_loss = attention_mask.view(-1) == 1\n",
        "                active_logits = logits.view(-1, self.num_labels)\n",
        "                active_labels = torch.where(\n",
        "                    active_loss, labels.view(-1), torch.tensor(loss_fct.ignore_index).type_as(labels)\n",
        "                )\n",
        "                loss = loss_fct(active_logits, active_labels)\n",
        "            else:\n",
        "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "            outputs = (loss,) + outputs\n",
        "\n",
        "        return outputs  # (loss), logits, (hidden_states), (attentions)"
      ],
      "metadata": {
        "id": "po2e0623X9Fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertConfig\n",
        "# Load the configuration from the pre-trained multilingual BERT model\n",
        "config = BertConfig.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "config.num_labels = 4  # Update the number of labels to the number of unique labels in your dataset\n",
        "\n",
        "# Instantiate the custom model for token classification\n",
        "model = ModifiedBertForTokenClassification(config)"
      ],
      "metadata": {
        "id": "dnM7y_rwY6QE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(model, optimizer, train_dataloader, val_dataloader, epochs=5, device=\"cpu\"):\n",
        "    model.to(device)\n",
        "    best_f1_score = 0\n",
        "    best_model = None\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()  # Set the model to training mode\n",
        "        total_train_loss = 0\n",
        "\n",
        "        for batch in train_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs[0] if isinstance(outputs, tuple) else outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "        average_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()  # Set the model to evaluation mode\n",
        "        total_val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_dataloader:\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                labels = batch['labels'].to(device)\n",
        "\n",
        "                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                loss = outputs[0] if isinstance(outputs, tuple) else outputs.loss\n",
        "                total_val_loss += loss.item()\n",
        "\n",
        "        average_val_loss = total_val_loss / len(val_dataloader)\n",
        "        print(f\"Epoch {epoch}: Average training loss: {average_train_loss}, Average validation loss: {average_val_loss}\")\n",
        "        # Your evaluatemodel function here should return the F1\n",
        "        f1_score_val = evaluatemodel(model, val_dataloader, device, label_to_id)\n",
        "        print(\"Validation F1 Score:\", f1_score_val)\n",
        "\n",
        "\n",
        "\n",
        "    return best_model"
      ],
      "metadata": {
        "id": "2DAwU4TkZRGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def evaluatemodel(model, dataloader, device, label_to_id):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs[0] if isinstance(outputs, tuple) else outputs.logits\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = labels.detach().cpu().numpy()\n",
        "\n",
        "            # Generate predictions and true label list, removing ignored index (-100)\n",
        "            batch_predictions = np.argmax(logits, axis=2)\n",
        "            for i, label in enumerate(label_ids):\n",
        "                batch_labels = []\n",
        "                batch_preds = []\n",
        "                for j, label_id in enumerate(label):\n",
        "                    if label_id != -100:  # Only consider labels that are not ignored\n",
        "                        batch_labels.append(label_id)\n",
        "                        batch_preds.append(batch_predictions[i][j])\n",
        "                true_labels.append(batch_labels)\n",
        "                predictions.append(batch_preds)\n",
        "\n",
        "    # Flatten the lists and remove padding (-100) labels\n",
        "    flat_predictions = [p for sublist in predictions for p in sublist]\n",
        "    flat_true_labels = [l for sublist in true_labels for l in sublist]\n",
        "\n",
        "    # Calculate F1 score using sklearn's utility\n",
        "    f1 = f1_score(flat_true_labels, flat_predictions, average='weighted')\n",
        "\n",
        "    return f1\n"
      ],
      "metadata": {
        "id": "rvasSPkTabxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train= preprocess_data(PATH_TRAIN, urdu_tokenizer, label_to_id, max_length=128)\n",
        "dataset_val = preprocess_data(PATH_VAL, urdu_tokenizer,label_to_id, max_length=128)\n",
        "dataset_test = preprocess_data(PATH_TEST, urdu_tokenizer,label_to_id, max_length=128)"
      ],
      "metadata": {
        "id": "qYxdWHOObCj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmXzJZnyhpGU",
        "outputId": "5af0f9c5-ca68-489a-ac6b-a086f2784ec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.UrduNERDataset at 0x7cff90112ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Assume dataset_train, dataset_val, and dataset_test are instances of UrduNERDataset\n",
        "train_dataloader = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
        "val_dataloader = DataLoader(dataset_val, batch_size=32, shuffle=False)\n",
        "test_dataloader = DataLoader(dataset_test, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "VH6TIV9mbkR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tensor_dataset = TensorDataset(train_tensors_input_ids, train_tensors_input_mask, train_tensors_label_ids)\n",
        "val_tensor_dataset = TensorDataset(val_tensors_input_ids, val_tensors_input_mask, val_tensors_label_ids)\n",
        "test_tensor_dataset = TensorDataset(test_tensors_input_ids, test_tensors_input_mask, test_tensors_label_ids)\n"
      ],
      "metadata": {
        "id": "fCjXplHWb6W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_tensor_dataset, batch_size=1)\n",
        "val_dataloader = DataLoader(val_tensor_dataset, batch_size=1)\n",
        "test_dataloader = DataLoader(test_tensor_dataset, batch_size=1)"
      ],
      "metadata": {
        "id": "14fBiCVAcLT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW\n",
        "FULL_FINETUNE = True\n",
        "# Replace 'urdu_ner_model' with the actual name of your model instance\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'LayerNorm.weight']  # 'gamma' and 'beta' are replaced with 'LayerNorm.weight'\n",
        "\n",
        "optimizer_grouped_parameters = []\n",
        "\n",
        "if FULL_FINETUNE:\n",
        "    print('ALL FINETUNE')\n",
        "    # If FULL_FINETUNE is True, we will fine-tune all the parameters\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay': 0.01},  # Corrected 'weight_decay_rate' to 'weight_decay'\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay': 0.0}\n",
        "    ]\n",
        "else:\n",
        "    print('NO ALL FINETUNE')\n",
        "    # If FULL_FINETUNE is False, we will only fine-tune the classifier layer parameters\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': model.classifier.parameters(),\n",
        "         'weight_decay': 0.01}  # Corrected 'weight_decay_rate' to 'weight_decay'\n",
        "    ]\n",
        "\n",
        "# Initialize the optimizer\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0VxwjcscUpa",
        "outputId": "eda115a1-0910-42cf-b6b7-214ffd224dc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ALL FINETUNE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = train(model, optimizer, train_dataloader, val_dataloader, epochs=5, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0blEsDid-sx",
        "outputId": "698c4011-4ac3-4b09-b5be-b7c0dd444b38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Average training loss: 0.4511543810367584, Average validation loss: 0.5202686190605164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 1/1 [00:07<00:00,  7.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation F1 Score: 0.8658008658008658\n",
            "Epoch 1: Average training loss: 0.3854222893714905, Average validation loss: 0.4530276954174042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 1/1 [00:07<00:00,  7.65s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation F1 Score: 0.8658008658008658\n",
            "Epoch 2: Average training loss: 0.3312543034553528, Average validation loss: 0.4104750156402588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 1/1 [00:07<00:00,  7.73s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation F1 Score: 0.8658008658008658\n",
            "Epoch 3: Average training loss: 0.29968294501304626, Average validation loss: 0.3889240622520447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 1/1 [00:07<00:00,  7.79s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation F1 Score: 0.8658008658008658\n",
            "Epoch 4: Average training loss: 0.3086167275905609, Average validation loss: 0.3887269198894501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 1/1 [00:07<00:00,  7.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation F1 Score: 0.8658008658008658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_entities(sentence, model, tokenizer, label_to_id, id_to_label, device):\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize the sentence and map tokens to their IDs\n",
        "    encoded_sentence = tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        max_length=128,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    input_ids = encoded_sentence['input_ids'].to(device)\n",
        "    attention_mask = encoded_sentence['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Get model predictions\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs[0] if isinstance(outputs, tuple) else outputs.logits\n",
        "\n",
        "        # Get the most likely prediction for each token\n",
        "        predictions = torch.argmax(logits, dim=2)\n",
        "\n",
        "    # Convert predictions to labels\n",
        "    predicted_label_ids = predictions[0].tolist()  # Get the first batch\n",
        "    # Remove the predictions for [CLS] and [SEP]\n",
        "    predicted_label_ids = predicted_label_ids[1:len(sentence.split())+1]\n",
        "\n",
        "    predicted_labels = [id_to_label[label_id] for label_id in predicted_label_ids]\n",
        "\n",
        "    # Combine tokens and labels\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "    tokens = tokens[1:len(sentence.split())+1]  # Remove [CLS] and [SEP]\n",
        "    return list(zip(tokens, predicted_labels))\n",
        "\n",
        "# Usage\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "sentence = \"اسلام باد عالمی بینک خیبرپختونخوا کے قبائلی اضلاع میں عسکریت پسندی سے پیدا ہونے والے بحران سے متاثرہ خاندانوں کی جلد بحالی بچوں کی صحت کی بہتری اور شہری مراکز ترسیل میں معاونت کے لیے فنڈز فراہم کرے گااس منصوبے کے لیے عالمی بینک ملٹی ڈونر ٹرسٹ کے تحت ایک کروڑ 20 لاکھ ڈالر فراہم کرے گا جس کے تحت شہریوں کی سہولت کے مراکز قائم کیے جائیں گے جو پوری قبائلی بادی اور اس سے منسلک اضلاع کو خدمات فراہم کرے گاڈان اخبار کی رپورٹ کے مطابق یہ جولائی 2019 میں ایک کروڑ 50 لاکھ ڈالر کی منظوری کے بعد سے منصوبے کی تیسری فنانسنگ ہوگییہ بھی پڑھیں ئندہ سال تک پاکستان میں غربت میں اضافے کا امکان ہے عالمی بینکان سہولیات کے مراکز کے ذریعے منتخب خدمات فراہم کی جائیں گی جس میں وائٹل رجسٹریشن سروس وی ایس سول رجسٹریشن منیجمنٹ سسٹم سی ایم ایس اور نادرا ای سہولت شامل ہے\"\n",
        "entities = predict_entities(sentence, model,tokenizer, label_to_id, id_to_label, device)\n",
        "\n",
        "# Print the tokens with their predicted entity labels\n",
        "for token, label in entities:\n",
        "    print(f\"{token}: {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6sgBeBefpE4",
        "outputId": "f126affe-3f9c-4d67-f81c-76f3782f4441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "اسلام: Other\n",
            "با: Other\n",
            "##د: Other\n",
            "عالمی: Other\n",
            "بین: Other\n",
            "##ک: Other\n",
            "خ: Other\n",
            "##یب: Other\n",
            "##ر: Other\n",
            "##پ: Other\n",
            "##خت: Other\n",
            "##ون: Other\n",
            "##خ: Other\n",
            "##وا: Other\n",
            "کے: Other\n",
            "ق: Other\n",
            "##با: Other\n",
            "##ئل: Other\n",
            "##ی: Other\n",
            "ا: Other\n",
            "##ضل: Other\n",
            "##اع: Other\n",
            "میں: Other\n",
            "ع: Other\n",
            "##س: Other\n",
            "##کری: Other\n",
            "##ت: Other\n",
            "پس: Other\n",
            "##ندی: Other\n",
            "سے: Other\n",
            "پیدا: Other\n",
            "ہونے: Other\n",
            "والے: Other\n",
            "ب: Other\n",
            "##حر: Other\n",
            "##ان: Other\n",
            "سے: Other\n",
            "م: Other\n",
            "##تا: Other\n",
            "##ثر: Other\n",
            "##ہ: Other\n",
            "خاندان: Other\n",
            "##وں: Other\n",
            "کی: Other\n",
            "جلد: Other\n",
            "ب: Other\n",
            "##حال: Other\n",
            "##ی: Other\n",
            "ب: Other\n",
            "##چ: Other\n",
            "##وں: Other\n",
            "کی: Other\n",
            "ص: Other\n",
            "##حت: Other\n",
            "کی: Other\n",
            "بہت: Other\n",
            "##ری: Other\n",
            "اور: Other\n",
            "شہر: Other\n",
            "##ی: Other\n",
            "م: Other\n",
            "##را: Other\n",
            "##کز: Other\n",
            "تر: Other\n",
            "##سی: Other\n",
            "##ل: Other\n",
            "میں: Other\n",
            "مع: Other\n",
            "##اون: Other\n",
            "##ت: Other\n",
            "کے: Other\n",
            "لیے: Other\n",
            "فن: Other\n",
            "##ڈ: Other\n",
            "##ز: Other\n",
            "ف: Other\n",
            "##را: Other\n",
            "##ہم: Other\n",
            "کر: Other\n",
            "##ے: Other\n",
            "گا: Other\n",
            "##اس: Other\n",
            "من: Other\n",
            "##ص: Other\n",
            "##وب: Other\n",
            "##ے: Other\n",
            "کے: Other\n",
            "لیے: Other\n",
            "عالمی: Other\n",
            "بین: Other\n",
            "##ک: Other\n",
            "مل: Other\n",
            "##ٹی: Other\n",
            "ڈ: Other\n",
            "##ون: Other\n",
            "##ر: Other\n",
            "ٹ: Other\n",
            "##رس: Other\n",
            "##ٹ: Other\n",
            "کے: Other\n",
            "تحت: Other\n",
            "ایک: Other\n",
            "کر: Other\n",
            "##و: Other\n",
            "##ڑ: Other\n",
            "20: Other\n",
            "لا: Other\n",
            "##کھ: Other\n",
            "ڈ: Other\n",
            "##ال: Other\n",
            "##ر: Other\n",
            "ف: Other\n",
            "##را: Other\n",
            "##ہم: Other\n",
            "کر: Other\n",
            "##ے: Other\n",
            "گا: Other\n",
            "جس: Other\n",
            "کے: Other\n",
            "تحت: Other\n",
            "شہر: Other\n",
            "##یوں: Other\n",
            "کی: Other\n",
            "س: Other\n",
            "##ہ: Other\n",
            "##ولت: Other\n",
            "[SEP]: Other\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ubEBnZRD9Vsx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}